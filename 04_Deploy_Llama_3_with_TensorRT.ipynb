{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01ec8829-f4f5-422b-b2de-f6adde6e98ca",
   "metadata": {},
   "source": [
    "# Deploy Llama3 with TensorRT-LLM\n",
    "\n",
    "Welcome!\n",
    "\n",
    "In this notebook, we will walk through on converting Mistral into the TensorRT format. TensorRT-LLM provides users with an easy-to-use Python API to define Large Language Models (LLMs) and build TensorRT engines that contain state-of-the-art optimizations to perform inference efficiently on NVIDIA GPUs.\n",
    "\n",
    "Once the TensorRT engine is build, you can use the run.py script provided at the end of this notebook or use this engine as in input to the Triton Inference Server.\n",
    "\n",
    "See the [Github repo](https://github.com/NVIDIA/TensorRT-LLM) for more examples and documentation!\n",
    "\n",
    "Deployment powered by [Brev.dev](https://twitter.com/brevdev) and the link for the [notebook](https://console.brev.dev/notebook/llama3-tensorrtllm-deployment).\n",
    "\n",
    "## Step 1 - Install TensorRT-LLM\n",
    "\n",
    "We first install TensorRT-LLM, which is already installed in the `nlp-1.3` and `Llama3` Jupyter kernels. You can choose either of these to run the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9dc104-c6a1-4195-a7c3-7f7628c913b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorrt_llm -U --pre --extra-index-url https://pypi.nvidia.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf2bb1d-81b2-4f33-8bae-e87388524265",
   "metadata": {},
   "source": [
    "## Step 2 - Download Llama3 model weights\n",
    "\n",
    "Llama3 is a gated model which means you'll need to request approval on their respository and generate a HF token. This usually takes about 20 minutes! The good news is that we have already downloaded the Llama3 model, which is located at `/data/ai/models/nlp/llama/models_llama3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaa79d9-b100-4bbd-aee9-72e8cf636c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148af093-09c4-4623-a506-6da8e4f00e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# huggingface_hub.login(\"<ENTER TOKEN HERE>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb2467f-2d91-4ee0-99f9-cefe88036dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# huggingface_hub.snapshot_download(\"meta-llama/Meta-Llama-3-8B-Instruct\", local_dir=\"llama3-hf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43c3c6f-b5de-4a6e-a485-d294bbeb7edf",
   "metadata": {},
   "source": [
    "## Step 3 - Convert checkpoints into safetensors and build the TRT engine\n",
    "\n",
    "There are 2 substeps here. The first is converting the raw huggingface model into safetensors which is a safe and fast format for storing tensors.\n",
    "\n",
    "Next we build the TensorRT engine. This is where the magic happens. We take the converted safetensors model and convert it into a `TensorRT engine`. Engines are optimized versions of models built to run lightening fast on the current machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3a1cb7f-f8a9-4113-bb8d-fa7388c64681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-10 14:23:48--  https://raw.githubusercontent.com/NVIDIA/TensorRT-LLM/main/examples/llama/convert_checkpoint.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 17658 (17K) [text/plain]\n",
      "Saving to: ‘convert_checkpoint.py’\n",
      "\n",
      "convert_checkpoint. 100%[===================>]  17.24K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-05-10 14:23:48 (43.5 MB/s) - ‘convert_checkpoint.py’ saved [17658/17658]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -L https://raw.githubusercontent.com/NVIDIA/TensorRT-LLM/main/examples/llama/convert_checkpoint.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74b4b9d7-da6e-4d19-b5bb-c8f0cd49e8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/apps/llama/3/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "--------------------------------------------------------------------------\n",
      "WARNING: There was an error initializing an OpenFabrics device.\n",
      "\n",
      "  Local host:   c0904a-s17\n",
      "  Local device: mlx5_1\n",
      "--------------------------------------------------------------------------\n",
      "[TensorRT-LLM] TensorRT-LLM version: 0.10.0.dev2024050700\n",
      "0.10.0.dev2024050700\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:14<00:00,  3.61s/it]\n",
      "Weights loaded. Total time: 00:00:10\n",
      "Total time of converting checkpoints: 00:01:02\n"
     ]
    }
   ],
   "source": [
    "!python convert_checkpoint.py --model_dir /data/ai/models/nlp/llama/models_llama3/Meta-Llama-3-8B-Instruct-hf \\\n",
    "    --output_dir ./llama3-safetensors \\\n",
    "    --dtype bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "005a0b83-3823-4e99-854c-0812b7bbbccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/apps/llama/3/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "--------------------------------------------------------------------------\n",
      "WARNING: There was an error initializing an OpenFabrics device.\n",
      "\n",
      "  Local host:   c0904a-s17\n",
      "  Local device: mlx5_1\n",
      "--------------------------------------------------------------------------\n",
      "[TensorRT-LLM] TensorRT-LLM version: 0.10.0.dev2024050700\n",
      "[05/10/2024-16:05:37] [TRT-LLM] [I] Set bert_attention_plugin to float16.\n",
      "[05/10/2024-16:05:37] [TRT-LLM] [I] Set gpt_attention_plugin to bfloat16.\n",
      "[05/10/2024-16:05:37] [TRT-LLM] [I] Set gemm_plugin to bfloat16.\n",
      "[05/10/2024-16:05:37] [TRT-LLM] [I] Set nccl_plugin to float16.\n",
      "[05/10/2024-16:05:37] [TRT-LLM] [I] Set lookup_plugin to None.\n",
      "[05/10/2024-16:05:37] [TRT-LLM] [I] Set lora_plugin to None.\n",
      "[05/10/2024-16:05:37] [TRT-LLM] [I] Set moe_plugin to float16.\n",
      "[05/10/2024-16:05:37] [TRT-LLM] [I] Set mamba_conv1d_plugin to float16.\n",
      "[05/10/2024-16:05:37] [TRT-LLM] [I] Set context_fmha to True.\n",
      "[05/10/2024-16:05:37] [TRT-LLM] [I] Set context_fmha_fp32_acc to False.\n",
      "[05/10/2024-16:05:37] [TRT-LLM] [I] Set paged_kv_cache to True.\n",
      "[05/10/2024-16:05:37] [TRT-LLM] [I] Set remove_input_padding to True.\n",
      "[05/10/2024-16:05:37] [TRT-LLM] [I] Set use_custom_all_reduce to True.\n",
      "[05/10/2024-16:05:37] [TRT-LLM] [I] Set multi_block_mode to False.\n",
      "[05/10/2024-16:05:37] [TRT-LLM] [I] Set enable_xqa to True.\n",
      "[05/10/2024-16:05:37] [TRT-LLM] [I] Set attention_qk_half_accumulation to False.\n",
      "[05/10/2024-16:05:37] [TRT-LLM] [I] Set tokens_per_block to 128.\n",
      "[05/10/2024-16:05:37] [TRT-LLM] [I] Set use_paged_context_fmha to False.\n",
      "[05/10/2024-16:05:37] [TRT-LLM] [I] Set use_fp8_context_fmha to False.\n",
      "[05/10/2024-16:05:37] [TRT-LLM] [I] Set use_context_fmha_for_generation to False.\n",
      "[05/10/2024-16:05:37] [TRT-LLM] [I] Set multiple_profiles to False.\n",
      "[05/10/2024-16:05:37] [TRT-LLM] [I] Set paged_state to True.\n",
      "[05/10/2024-16:05:37] [TRT-LLM] [I] Set streamingllm to False.\n",
      "[05/10/2024-16:05:37] [TRT-LLM] [W] remove_input_padding is enabled, while max_num_tokens is not set, setting to max_batch_size*max_input_len. \n",
      "It may not be optimal to set max_num_tokens=max_batch_size*max_input_len when remove_input_padding is enabled, because the number of packed input tokens are very likely to be smaller, we strongly recommend to set max_num_tokens according to your workloads.\n",
      "[05/10/2024-16:05:37] [TRT-LLM] [W] remove_input_padding is enabled, while opt_num_tokens is not set, setting to max_batch_size*max_beam_width. \n",
      "\n",
      "[05/10/2024-16:05:41] [TRT] [I] [MemUsageChange] Init CUDA: CPU +13, GPU +0, now: CPU 383, GPU 537 (MiB)\n",
      "[05/10/2024-16:05:44] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +1926, GPU +348, now: CPU 2445, GPU 885 (MiB)\n",
      "[05/10/2024-16:05:44] [TRT] [W] profileSharing0806 is on by default in TensorRT 10.0. This flag is deprecated and has no effect.\n",
      "[05/10/2024-16:05:44] [TRT-LLM] [I] Set nccl_plugin to None.\n",
      "[05/10/2024-16:05:44] [TRT-LLM] [I] Set use_custom_all_reduce to True.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/vocab_embedding/GATHER_0_output_0 and LLaMAForCausalLM/transformer/layers/0/input_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/0/input_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/0/input_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/0/ELEMENTWISE_SUM_0_output_0 and LLaMAForCausalLM/transformer/layers/0/post_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/0/post_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/0/post_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/0/ELEMENTWISE_SUM_1_output_0 and LLaMAForCausalLM/transformer/layers/1/input_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/1/input_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/1/input_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/1/ELEMENTWISE_SUM_0_output_0 and LLaMAForCausalLM/transformer/layers/1/post_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/1/post_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/1/post_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/1/ELEMENTWISE_SUM_1_output_0 and LLaMAForCausalLM/transformer/layers/2/input_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/2/input_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/2/input_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/2/ELEMENTWISE_SUM_0_output_0 and LLaMAForCausalLM/transformer/layers/2/post_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/2/post_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/2/post_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/2/ELEMENTWISE_SUM_1_output_0 and LLaMAForCausalLM/transformer/layers/3/input_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/3/input_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/3/input_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/3/ELEMENTWISE_SUM_0_output_0 and LLaMAForCausalLM/transformer/layers/3/post_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/3/post_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/3/post_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/3/ELEMENTWISE_SUM_1_output_0 and LLaMAForCausalLM/transformer/layers/4/input_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/4/input_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/4/input_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/4/ELEMENTWISE_SUM_0_output_0 and LLaMAForCausalLM/transformer/layers/4/post_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/4/post_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/4/post_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/4/ELEMENTWISE_SUM_1_output_0 and LLaMAForCausalLM/transformer/layers/5/input_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/5/input_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/5/input_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/5/ELEMENTWISE_SUM_0_output_0 and LLaMAForCausalLM/transformer/layers/5/post_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/5/post_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/5/post_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/5/ELEMENTWISE_SUM_1_output_0 and LLaMAForCausalLM/transformer/layers/6/input_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/6/input_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/6/input_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/6/ELEMENTWISE_SUM_0_output_0 and LLaMAForCausalLM/transformer/layers/6/post_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/6/post_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/6/post_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/6/ELEMENTWISE_SUM_1_output_0 and LLaMAForCausalLM/transformer/layers/7/input_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/7/input_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/7/input_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/7/ELEMENTWISE_SUM_0_output_0 and LLaMAForCausalLM/transformer/layers/7/post_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/7/post_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/7/post_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/7/ELEMENTWISE_SUM_1_output_0 and LLaMAForCausalLM/transformer/layers/8/input_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/8/input_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/8/input_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/8/ELEMENTWISE_SUM_0_output_0 and LLaMAForCausalLM/transformer/layers/8/post_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/8/post_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/8/post_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/8/ELEMENTWISE_SUM_1_output_0 and LLaMAForCausalLM/transformer/layers/9/input_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/9/input_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/9/input_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/9/ELEMENTWISE_SUM_0_output_0 and LLaMAForCausalLM/transformer/layers/9/post_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/9/post_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/9/post_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/9/ELEMENTWISE_SUM_1_output_0 and LLaMAForCausalLM/transformer/layers/10/input_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/10/input_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/10/input_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/10/ELEMENTWISE_SUM_0_output_0 and LLaMAForCausalLM/transformer/layers/10/post_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/10/post_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/10/post_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/10/ELEMENTWISE_SUM_1_output_0 and LLaMAForCausalLM/transformer/layers/11/input_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/11/input_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/11/input_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/11/ELEMENTWISE_SUM_0_output_0 and LLaMAForCausalLM/transformer/layers/11/post_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/11/post_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/11/post_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/11/ELEMENTWISE_SUM_1_output_0 and LLaMAForCausalLM/transformer/layers/12/input_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/12/input_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/12/input_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/12/ELEMENTWISE_SUM_0_output_0 and LLaMAForCausalLM/transformer/layers/12/post_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/12/post_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/12/post_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/12/ELEMENTWISE_SUM_1_output_0 and LLaMAForCausalLM/transformer/layers/13/input_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/13/input_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/13/input_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/13/ELEMENTWISE_SUM_0_output_0 and LLaMAForCausalLM/transformer/layers/13/post_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/13/post_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/13/post_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/13/ELEMENTWISE_SUM_1_output_0 and LLaMAForCausalLM/transformer/layers/14/input_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/14/input_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/14/input_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/14/ELEMENTWISE_SUM_0_output_0 and LLaMAForCausalLM/transformer/layers/14/post_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/14/post_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/14/post_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/14/ELEMENTWISE_SUM_1_output_0 and LLaMAForCausalLM/transformer/layers/15/input_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/15/input_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/15/input_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/15/ELEMENTWISE_SUM_0_output_0 and LLaMAForCausalLM/transformer/layers/15/post_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/15/post_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/15/post_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/15/ELEMENTWISE_SUM_1_output_0 and LLaMAForCausalLM/transformer/layers/16/input_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/16/input_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/16/input_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/16/ELEMENTWISE_SUM_0_output_0 and LLaMAForCausalLM/transformer/layers/16/post_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/16/post_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/16/post_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/16/ELEMENTWISE_SUM_1_output_0 and LLaMAForCausalLM/transformer/layers/17/input_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/17/input_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/17/input_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/17/ELEMENTWISE_SUM_0_output_0 and LLaMAForCausalLM/transformer/layers/17/post_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/17/post_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/17/post_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/17/ELEMENTWISE_SUM_1_output_0 and LLaMAForCausalLM/transformer/layers/18/input_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/18/input_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/18/input_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/18/ELEMENTWISE_SUM_0_output_0 and LLaMAForCausalLM/transformer/layers/18/post_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/18/post_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/18/post_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/18/ELEMENTWISE_SUM_1_output_0 and LLaMAForCausalLM/transformer/layers/19/input_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/19/input_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/19/input_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/19/ELEMENTWISE_SUM_0_output_0 and LLaMAForCausalLM/transformer/layers/19/post_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/19/post_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/19/post_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/19/ELEMENTWISE_SUM_1_output_0 and LLaMAForCausalLM/transformer/layers/20/input_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/20/input_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/20/input_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/20/ELEMENTWISE_SUM_0_output_0 and LLaMAForCausalLM/transformer/layers/20/post_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/20/post_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/20/post_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/20/ELEMENTWISE_SUM_1_output_0 and LLaMAForCausalLM/transformer/layers/21/input_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/21/input_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/21/input_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/21/ELEMENTWISE_SUM_0_output_0 and LLaMAForCausalLM/transformer/layers/21/post_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/21/post_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/21/post_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/21/ELEMENTWISE_SUM_1_output_0 and LLaMAForCausalLM/transformer/layers/22/input_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/22/input_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/22/input_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/22/ELEMENTWISE_SUM_0_output_0 and LLaMAForCausalLM/transformer/layers/22/post_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/22/post_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/22/post_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/22/ELEMENTWISE_SUM_1_output_0 and LLaMAForCausalLM/transformer/layers/23/input_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/23/input_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/23/input_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/23/ELEMENTWISE_SUM_0_output_0 and LLaMAForCausalLM/transformer/layers/23/post_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/23/post_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/23/post_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/23/ELEMENTWISE_SUM_1_output_0 and LLaMAForCausalLM/transformer/layers/24/input_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/24/input_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/24/input_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/24/ELEMENTWISE_SUM_0_output_0 and LLaMAForCausalLM/transformer/layers/24/post_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/24/post_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/24/post_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/24/ELEMENTWISE_SUM_1_output_0 and LLaMAForCausalLM/transformer/layers/25/input_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/25/input_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/25/input_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/25/ELEMENTWISE_SUM_0_output_0 and LLaMAForCausalLM/transformer/layers/25/post_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/25/post_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/25/post_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/25/ELEMENTWISE_SUM_1_output_0 and LLaMAForCausalLM/transformer/layers/26/input_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/26/input_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/26/input_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/26/ELEMENTWISE_SUM_0_output_0 and LLaMAForCausalLM/transformer/layers/26/post_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/26/post_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/26/post_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/26/ELEMENTWISE_SUM_1_output_0 and LLaMAForCausalLM/transformer/layers/27/input_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/27/input_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/27/input_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/27/ELEMENTWISE_SUM_0_output_0 and LLaMAForCausalLM/transformer/layers/27/post_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/27/post_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/27/post_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/27/ELEMENTWISE_SUM_1_output_0 and LLaMAForCausalLM/transformer/layers/28/input_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/28/input_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/28/input_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/28/ELEMENTWISE_SUM_0_output_0 and LLaMAForCausalLM/transformer/layers/28/post_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/28/post_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/28/post_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/28/ELEMENTWISE_SUM_1_output_0 and LLaMAForCausalLM/transformer/layers/29/input_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/29/input_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/29/input_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/29/ELEMENTWISE_SUM_0_output_0 and LLaMAForCausalLM/transformer/layers/29/post_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/29/post_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/29/post_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/29/ELEMENTWISE_SUM_1_output_0 and LLaMAForCausalLM/transformer/layers/30/input_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/30/input_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/30/input_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/30/ELEMENTWISE_SUM_0_output_0 and LLaMAForCausalLM/transformer/layers/30/post_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/30/post_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/30/post_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/30/ELEMENTWISE_SUM_1_output_0 and LLaMAForCausalLM/transformer/layers/31/input_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/31/input_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/31/input_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/31/ELEMENTWISE_SUM_0_output_0 and LLaMAForCausalLM/transformer/layers/31/post_layernorm/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/31/post_layernorm/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/layers/31/post_layernorm/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/layers/31/ELEMENTWISE_SUM_1_output_0 and LLaMAForCausalLM/transformer/ln_f/SHUFFLE_0_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT] [W] IElementWiseLayer with inputs LLaMAForCausalLM/transformer/ln_f/REDUCE_AVG_0_output_0 and LLaMAForCausalLM/transformer/ln_f/SHUFFLE_1_output_0: first input has type BFloat16 but second input has type Float.\n",
      "[05/10/2024-16:05:44] [TRT-LLM] [I] Build TensorRT engine Unnamed Network 0\n",
      "[05/10/2024-16:05:44] [TRT] [W] Unused Input: position_ids\n",
      "[05/10/2024-16:05:44] [TRT] [W] [RemoveDeadLayers] Input Tensor position_ids is unused or used only at compile-time, but is not being removed.\n",
      "[05/10/2024-16:05:44] [TRT] [I] Global timing cache in use. Profiling results in this builder pass will be stored.\n",
      "[05/10/2024-16:05:53] [TRT] [I] [GraphReduction] The approximate region cut reduction algorithm is called.\n",
      "[05/10/2024-16:05:53] [TRT] [I] Detected 14 inputs and 1 output network tensors.\n",
      "[05/10/2024-16:06:10] [TRT] [I] Total Host Persistent Memory: 103808\n",
      "[05/10/2024-16:06:10] [TRT] [I] Total Device Persistent Memory: 0\n",
      "[05/10/2024-16:06:10] [TRT] [I] Total Scratch Memory: 33559168\n",
      "[05/10/2024-16:06:10] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 592 steps to complete.\n",
      "[05/10/2024-16:06:10] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 29.0165ms to assign 17 blocks to 592 nodes requiring 201332224 bytes.\n",
      "[05/10/2024-16:06:10] [TRT] [I] Total Activation Memory: 201330688\n",
      "[05/10/2024-16:06:10] [TRT] [I] Total Weights Memory: 16064716800\n",
      "[05/10/2024-16:06:10] [TRT] [I] Engine generation completed in 25.635 seconds.\n",
      "[05/10/2024-16:06:10] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 2004 MiB, GPU 15320 MiB\n",
      "[05/10/2024-16:06:15] [TRT] [I] [MemUsageStats] Peak memory usage during Engine building and serialization: CPU: 34998 MiB\n",
      "[05/10/2024-16:06:15] [TRT-LLM] [I] Total time of building Unnamed Network 0: 00:00:30\n",
      "[05/10/2024-16:06:15] [TRT] [I] Serialized 26 bytes of code generator cache.\n",
      "[05/10/2024-16:06:15] [TRT] [I] Serialized 169121 bytes of compilation cache.\n",
      "[05/10/2024-16:06:15] [TRT] [I] Serialized 12 timing cache entries\n",
      "[05/10/2024-16:06:15] [TRT-LLM] [I] Timing cache serialized to model.cache\n",
      "[05/10/2024-16:06:15] [TRT-LLM] [I] Serializing engine to ./llama3engine_bf16_1gpu/rank0.engine...\n",
      "[05/10/2024-16:06:28] [TRT-LLM] [I] Engine serialized. Total time: 00:00:13\n",
      "[05/10/2024-16:06:29] [TRT-LLM] [I] Total time of building all engines: 00:00:51\n"
     ]
    }
   ],
   "source": [
    "!trtllm-build --checkpoint_dir llama3-safetensors \\\n",
    "    --output_dir ./llama3engine_bf16_1gpu \\\n",
    "    --gpt_attention_plugin bfloat16 \\\n",
    "    --gemm_plugin bfloat16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ef031d-e286-434c-851d-e2bf82ce772a",
   "metadata": {},
   "source": [
    "## Step 4 - Run the model using the example script!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc47b334-6b56-419a-858e-3fe60e5bead3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'TensorRT-LLM'...\n",
      "remote: Enumerating objects: 14993, done.\u001b[K\n",
      "remote: Counting objects: 100% (7097/7097), done.\u001b[K\n",
      "remote: Compressing objects: 100% (1958/1958), done.\u001b[K\n",
      "remote: Total 14993 (delta 5436), reused 6102 (delta 5086), pack-reused 7896\u001b[K\n",
      "Receiving objects: 100% (14993/14993), 204.58 MiB | 40.19 MiB/s, done.\n",
      "Resolving deltas: 100% (10606/10606), done.\n",
      "Updating files: 100% (2216/2216), done.\n",
      "Filtering content: 100% (14/14), 204.50 MiB | 129.91 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "# !git clone https://github.com/NVIDIA/TensorRT-LLM.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09de47af-35e4-49ee-8f3b-93134b6fb189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/apps/llama/3/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "--------------------------------------------------------------------------\n",
      "WARNING: There was an error initializing an OpenFabrics device.\n",
      "\n",
      "  Local host:   c0904a-s17\n",
      "  Local device: mlx5_1\n",
      "--------------------------------------------------------------------------\n",
      "[TensorRT-LLM] TensorRT-LLM version: 0.10.0.dev2024050700\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[TensorRT-LLM][INFO] Engine version 0.10.0.dev2024050700 found in the config file, assuming engine(s) built by new builder API.\n",
      "[TensorRT-LLM][WARNING] [json.exception.out_of_range.403] key 'cross_attention' not found\n",
      "[TensorRT-LLM][WARNING] Optional value for parameter cross_attention will not be set.\n",
      "[TensorRT-LLM][WARNING] Parameter layer_types cannot be read from json:\n",
      "[TensorRT-LLM][WARNING] [json.exception.out_of_range.403] key 'layer_types' not found\n",
      "[TensorRT-LLM][WARNING] [json.exception.type_error.302] type must be string, but is null\n",
      "[TensorRT-LLM][WARNING] Optional value for parameter quant_algo will not be set.\n",
      "[TensorRT-LLM][WARNING] [json.exception.type_error.302] type must be string, but is null\n",
      "[TensorRT-LLM][WARNING] Optional value for parameter kv_cache_quant_algo will not be set.\n",
      "[TensorRT-LLM][WARNING] [json.exception.out_of_range.403] key 'num_medusa_heads' not found\n",
      "[TensorRT-LLM][WARNING] Optional value for parameter num_medusa_heads will not be set.\n",
      "[TensorRT-LLM][WARNING] [json.exception.out_of_range.403] key 'max_draft_len' not found\n",
      "[TensorRT-LLM][WARNING] Optional value for parameter max_draft_len will not be set.\n",
      "[TensorRT-LLM][INFO] MPI size: 1, rank: 0\n",
      "[TensorRT-LLM][INFO] Loaded engine size: 15323 MiB\n",
      "[TensorRT-LLM][INFO] Allocated 192.00 MiB for execution context memory.\n",
      "[TensorRT-LLM][INFO] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +0, now: CPU 0, GPU 15320 (MiB)\n",
      "[TensorRT-LLM][INFO] Max KV cache pages per sequence: 1\n",
      "[TensorRT-LLM][INFO] Max tokens in paged KV cache: 467840. Allocating 61320724480 bytes.\n",
      "Input [Text 0]: \"How do I count to nine in French?\"\n",
      "Output [Text 0 Beam 0]: \"**\n",
      "To count to nine in French, you can say:\n",
      "1. Un (one)\n",
      "2. Deux (two)\n",
      "3. Trois (three)\n",
      "4. Quatre (four)\n",
      "5. Cinq (five)\n",
      "6. Six (six)\n",
      "7. Sept (seven)\n",
      "8. Huit (eight)\n",
      "9. Neuf (nine)\n",
      "\n",
      "I hope that helps! Let me know if you have any other questions.**\n",
      "\n",
      "\n",
      "\n",
      "**How do I count to ten in French?**\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "!python ./TensorRT-LLM/examples/run.py --engine_dir=llama3engine_bf16_1gpu \\\n",
    "    --max_output_len 100 \\\n",
    "    --tokenizer_dir /data/ai/models/nlp/llama/models_llama3/Meta-Llama-3-8B-Instruct-hf \\\n",
    "    --input_text \"How do I count to nine in French?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6b50a9-268f-43ef-87a6-5d1df307a0aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Llama3",
   "language": "python",
   "name": "llama3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
